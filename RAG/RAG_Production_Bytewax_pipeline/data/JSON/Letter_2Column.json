{
  "_id": {
    "$oid": ""
  },
  "originalName": "Letter_2Column.pdf",
  "path": "",
  "user": {
    "$oid": ""
  },
  "processed": "",
  "pinecone": "",
  "deleted": "",
  "fileHash": "",
  "figures_contents": "",
  "contents": [
    {
      "text": "Comment   www[dot]thelancet[dot]com/digital-health   Vol 5   March 2023\t e105  Published Online February 6, 2023 https://doi[dot]org/10[dot]1016/  S2589-7500(23)00019-5  Generating scholarly content with ChatGPT: ethical  challenges for medical publishing  The impact of generative artificial intelligence (AI) on  medical publishing practices is currently unknown.  However, as our experiences underline, generative AI  could have substantial ethical implications.  Chat Generative Pre-trained Transformer (ChatGPT;   OpenAI, San Francisco, CA, USA) is an AI chatbot released  in November, 2022[dot]1 Developed using human feedback  and freely accessible, the platform has already attracted  millions of interactions.2 When presented with a query,  ChatGPT will automatically generate a response, which  is based on thousands of internet sources, often without  further input from the user. Resultantly, individuals have  reportedly used ChatGPT to formulate university essays  and scholarly articles3 and, if prompted, the system can  deliver accompanying references. Given these accounts  and its popular usage, we requested that ChatGPT write  a Comment for The Lancet Digital Health about AI and  medical publishing ethics. We then asked ChatGPT how  the editorial team should address academic content  produced by AI. The results make for interesting reading  (appendix).   The functionality of ChatGPT highlights the growing   necessity of implementing robust AI author guidelines  in scholarly publishing. Ethical considerations abound  concerning copyright, attribution, plagiarism, and  authorship when AI produces academic text. These  concerns are especially pertinent because whether copy  is AI generated is currently imperceptible to human  readers and anti-plagiarism software. Studies across  various fields have already listed ChatGPT as an author,4  but whether generative AI fulfils the International  Committee of Medical Journal Editors\u2019 criteria for  authorship is a point of debate: can a chatbot really  provide approval for work and be accountable for its  contents? The Committee on Publication Ethics has  developed AI recommendations for editorial decision  making5 and the trade body for scholarly publishers, the  International Association of Scientific, Technical, and  Medical Publishers, produced a white paper on AI ethics.6  As technologies become better tailored to user needs  and more commonly adopted, we believe compre\u00ad hensive discussions about authorship policies are urgent  and essential. Elsevier, who publish the Lancet family of   journals, alongside other major publishers, have stated  that AI cannot be listed as an author and its use must be  properly acknowledged.7  ChatGPT is available to use without cost.1 However,   OpenAI\u2019s leadership have affirmed that free use is  temporary and the product will eventually be mon\u00ad etised.8 One commercial option for the platform could  conceivably involve some form of paywall, which might  entrench existing international inequalities in scholarly  publishing. Although institutions in socioeconomically  advantaged areas could probably afford access, those in  low-income and middle-income countries might not be  able to, thus widening existing disparities in knowledge  dissemination and scholarly publishing.  In our opinion, as the program remains freely available   in the short term, ChatGPT\u2019s ease of use and accessibility  could substantially increase scholarly output. ChatGPT  might democratise the dissemination of knowledge  since the chatbot can receive and produce copy in  multiple languages, circumventing English-language  requirements, which can be a publishing barrier  for speakers of other languages. Nonetheless, the  functionality of ChatGPT has the capacity to cause harm  by producing misleading or inaccurate content,3 thereby  eliciting concerns around scholarly misinformation. As  the so-called COVID-19 infodemic shows, the potential  spread of misinformation in medical publishing can  entail substantial societal hazards.9 Listed by OpenAI  as a limitation, \u201cChatGPT sometimes writes plausible- sounding but incorrect or nonsensical answers\u201d;1  interestingly, the chatbot itself highlighted this possi\u00ad bility when responding to us (appendix).   The early rollout of ChatGPT will inevitably spawn   competitors, potentially rendering this a far-reaching  problem. Accordingly, per ChatGPT\u2019s response to  our query, The Lancet Digital Health should \u201ccarefully  consider the ethical implications of publishing articles  produced by AI\u201d We would go further: as pioneers  of publishing ethics and academic standards, we call  on The Lancet Digital Health and the Lancet family to  initiate rigorous exchanges around the implications of  AI-generated content within scholarly publishing, with  a view to creating comprehensive guidance. ChatGPT\u2019s   See Online for appendix",
      "page_number": 1
    },
    {
      "text": "Comment  e106\t  www[dot]thelancet[dot]com/digital-health   Vol 5   March 2023  burgeoning popularity and our experiences illustrate  that the time for these conversations is now; after  all, can you really be sure that what you are currently  reading was written by human authors?  We declare no competing interests.  Copyright \u00a9 2023 The Author(s). Published by Elsevier Ltd. This is an Open  Access article under the CC BY-NC-ND 4[dot]0 license.  *Michael Liebrenz, Roman Schleifer, Anna Buadze,  Dinesh Bhugra, Alexander Smith michael[dot]liebrenz@unibe[dot]ch   Department of Forensic Psychiatry, University of Bern, 3012 Bern, Switzerland  (ML, RS, AS); Department of Psychiatry, Psychotherapy and Psychosomatics,  Psychiatric Hospital, Specialized Outpatient Clinic for ADHD, University of  Zurich, Zurich, Switzerland (AB); Dinesh Bhugra, Kings College London, London,  UK (DB)  1\t OpenAI. ChatGPT. 2022. https://openai[dot]com/blog/chatgpt/ (accessed  Dec 21, 2022).  2\t Grant N, Metz C. A New chat bot is a \u2018code red\u2019 for Google\u2019s search business.  The New York Times, Dec 21, 2022. https://www[dot]nytimes[dot]com/2022/12/21/ technology/ai-chatgpt-google-search.html (accessed Dec 23, 2022).  3\t Bowman E. AI bot ChatGPT stuns academics with essay-writing skills and  usability. NPR, Dec 19, 2022. https://www[dot]npr[dot]org/2022/12/19/1143912956/ chatgpt-ai-chatbot-homework-academia (accessed Dec 21, 2022).  4\t Frye B. Should using an AI text generator to produce academic writing be  plagiarism? SSRN 2022; published online Dec 20. https://ssrn[dot]com/ abstract=4292283 (preprint).  5\t Committee on Publication Ethics. Artificial intelligence (AI) in decision  making. 2021. https://doi[dot]org/10[dot]24318/9kvAgrnJ (accessed  Dec 20, 2022).  6\t International Association of Scientific, Technical, and Medical Publishers.  AI ethics in scholarly communication\u2014STM best practice principles for  ethical, trustworthy and human-centric AI. 2021. https://www[dot]stm-assoc[dot] org/2021_05_11_STM_AI_White_Paper_April2021.pdf (accessed  Dec 21, 2022).  7\t Elsevier. Publishing ethics. Elsevier. https://www[dot]elsevier[dot]com/about/ policies/publishing-ethics (accessed Feb 1, 2023).  8\t Karpf D. Money will kill ChatGPT\u2019s magic. The Atlantic, Dec 21, 2022.  https://www[dot]theatlantic[dot]com/technology/archive/2022/12/chatgpt-ai- chatbots-openai-cost-regulations/672539/ (accessed Dec 23, 2022).  9\t The Lancet Infectious Diseases. The COVID-19 infodemic. Lancet Infect Dis  2020; 20: 875.",
      "page_number": 2
    }
  ]
}